{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get current working directory :  /Users/aokoln/occupation-project\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print('Get current working directory : ', os.getcwd())\n",
    "\n",
    "#df = pd.read_csv('/Users/sima.sharifirad/career_designer_sima/Occupation Data 2023.csv')\n",
    "df = pd.read_csv('Occupation Data 2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CLASSID</th>\n",
       "      <th>CLASSID_NAME</th>\n",
       "      <th>AREAID</th>\n",
       "      <th>AREAID_NAME</th>\n",
       "      <th>OCCID</th>\n",
       "      <th>OCCID_NAME</th>\n",
       "      <th>EARN_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2031</td>\n",
       "      <td>4</td>\n",
       "      <td>Extended Proprietors</td>\n",
       "      <td>1125010702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51-7021</td>\n",
       "      <td>Furniture Finishers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>Extended Proprietors</td>\n",
       "      <td>17031470100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43-4111</td>\n",
       "      <td>Interviewers, Except Eligibility and Loan</td>\n",
       "      <td>31.011969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>9009150300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-2022</td>\n",
       "      <td>Physical Therapist Aides</td>\n",
       "      <td>17.508876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  CLASSID          CLASSID_NAME       AREAID AREAID_NAME    OCCID  \\\n",
       "0  2031        4  Extended Proprietors   1125010702         NaN  51-7021   \n",
       "1  2011        4  Extended Proprietors  17031470100         NaN  43-4111   \n",
       "2  2016        3         Self-Employed   9009150300         NaN  31-2022   \n",
       "\n",
       "                                  OCCID_NAME   EARN_AVG  \n",
       "0                        Furniture Finishers   0.000000  \n",
       "1  Interviewers, Except Eligibility and Loan  31.011969  \n",
       "2                   Physical Therapist Aides  17.508876  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "\n",
    "Step 1: Import the required libraries.\n",
    "\n",
    "Step 2: Preprocess the text data and split the data into training and testing sets.\n",
    "\n",
    "Step 3: Vectorize the 'OCCID_NAME' text data using TF-IDF.\n",
    "\n",
    "Step 4: Train an SVM classifier on the TF-IDF vectors.\n",
    "\n",
    "Step 5: Evaluate the model on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the required libraries.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the text data and split the data into training and testing sets.\n",
    "\n",
    "# Step 2a: Load the DataFrame and split the data into features and labels.\n",
    "# Assuming you already have a DataFrame named 'df' with columns 'OCCID_NAME' and 'CLASSID_NAME'\n",
    "\n",
    "X = df['OCCID_NAME']\n",
    "y = df['CLASSID_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random_state:\n",
    "\n",
    "The random_state parameter is used for reproducibility. \n",
    "In machine learning algorithms like *train_test_split*, random processes are involved,\n",
    "such as random shuffling of data during train-test splitting. \n",
    "\n",
    "Setting random_state to a fixed integer ensures that the random processes are performed in a predictable manner, \n",
    "and the same results can be reproduced each time the code is executed with the same value of random_state.\n",
    "\n",
    "This is helpful for debugging and obtaining consistent results in experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b: Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer:\n",
    "\n",
    "TfidfVectorizer is a class from the *scikit-learn* library that is used for converting text data into\n",
    "a numerical format called **Term Frequency-Inverse Document Frequency (TF-IDF)** vectors. \n",
    "It calculates the *TF-IDF* value for each word (term) in the text data, \n",
    "which is a measure of how important a word is in a particular document relative to the entire corpus of documents. \n",
    "\n",
    "*TF-IDF* helps to represent the text data in a way that emphasizes important words \n",
    "while downplaying common and uninformative words.\n",
    "\n",
    "\n",
    "#### fit_transform:\n",
    "\n",
    "*fit_transform* is a method in scikit-learn's vectorizers (like *TfidfVectorizer*) that combines two steps: \n",
    "1. fitting the vectorizer to the training data and \n",
    "2. transforming the training data into TF-IDF vectors. \n",
    "\n",
    "In the code, *fit_transform* is used on the training *data X_train* to learn \n",
    "the vocabulary and IDF statistics from the training data and \n",
    "then transform it into TF-IDF vectors represented as *X_train_tfidf*. \n",
    "\n",
    "The same vocabulary and IDF statistics learned from the training data are later used \n",
    "to transform the testing data into TF-IDF vectors using the transform method.\n",
    "\n",
    "\n",
    "#### tfidf_vectorizer:\n",
    "\n",
    "*tfidf_vectorizer* is an instance of the *TfidfVectorizer* class. \n",
    "\n",
    "It is created with specific parameters like *max_features* and *stop_words* to customize the vectorization process.\n",
    "\n",
    "Once *tfidf_vectorizer* is created, it can be used to transform the text data (both training and testing) \n",
    "into TF-IDF vectors using *fit_transform* and *transform* methods, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<80x198 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 278 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Vectorize the 'OCCID_NAME' text data using TF-IDF\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "# You can adjust max_features as needed\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "###### Having an issue with understanding data types and \n",
    "###### previewing what the data looks like in this code block:\n",
    "\n",
    "#X_train_tfidf.head(3)\n",
    "type(X_train_tfidf)\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF an example:\n",
    "\n",
    "We created a *TfidfVectorizer* instance without specifying any parameters. \n",
    "This means the vectorizer uses the default settings, \n",
    "including tokenization, lowercase conversion, and removing English stop words.\n",
    "\n",
    "We used *fit_transform* to transform the documents into TF-IDF vectors represented as *tfidf_matrix*.\n",
    "\n",
    "We obtained the feature names (words) learned by the vectorizer using *get_feature_names_out()*.\n",
    "\n",
    "We printed the *TF-IDF scores* for each term in each document.\n",
    "The TF-IDF score represents the importance of a term (word) in a specific document. \n",
    "Higher values indicate higher importance relative to the entire corpus.\n",
    "\n",
    "By analyzing the TF-IDF scores, you can observe the following:\n",
    "\n",
    "- Common words like \"the,\" \"is,\" \"and,\" \"a\" have low TF-IDF scores, because they appear in multiple documents and are less informative for distinguishing between documents.\n",
    "\n",
    "- Less common words like \"jumps,\" \"lazy,\" \"quick,\" \"brown,\" \"good,\" and \"friends\" have higher TF-IDF scores, because they are more specific to individual documents and provide more discriminative power.\n",
    "\n",
    "This simple analysis helps in understanding how TF-IDF works to \n",
    "represent text data as numerical vectors and highlights the importance of individual terms in different documents. \n",
    "\n",
    "tfidf link: <https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample corpus of documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"A fox and a dog are good friends\",\n",
    "    \"The dog is lazy but the fox is quick\"\n",
    "]\n",
    "\n",
    "# Step 1: Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Transform the documents into TF-IDF vectors\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (words) learned by the vectorizer\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Step 3: Print the TF-IDF scores for each term in each document\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    print(f\"Document {doc_idx + 1}:\")\n",
    "    for term_idx, term in enumerate(feature_names):\n",
    "        tfidf_score = tfidf_matrix[doc_idx, term_idx]\n",
    "        if tfidf_score > 0:\n",
    "            print(f\"{term}: {tfidf_score:.3f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM (Support Vector Machine):\n",
    "\n",
    "SVM is a popular supervised machine learning algorithm used for both classification and regression tasks. \n",
    "In the context of the code, we are using SVM for text classification, \n",
    "where each document (represented by its TF-IDF vector) is associated with a class label.\n",
    "\n",
    "The main idea behind SVM is to find a hyperplane that best separates the data into different classes. \n",
    "\n",
    "- For *binary classification*, the hyperplane separates the data into two classes by maximizing the margin (distance) between the classes. \n",
    "\n",
    "- For *multi-class classification*, like in this example, SVM uses various techniques (e.g., One-vs-Rest, One-vs-One) to handle multiple classes.\n",
    "\n",
    "\n",
    "#### kernel:\n",
    "\n",
    "The kernel parameter in SVM determines the *type of function used to transform the input data into \n",
    "a higher-dimensional space*, where it becomes easier to find a separating hyperplane. \n",
    "\n",
    "Different kernel functions can be used, such as 'linear', 'poly', 'rbf' (Radial Basis Function),'sigmoid', etc.\n",
    "\n",
    "In the code, we used the 'linear' kernel, which implies a linear hyperplane for separation. \n",
    "This kernel is suitable for cases where the data can be effectively separated by a straight line or plane. \n",
    "\n",
    "Other kernel functions can be used depending on the nature of the data and the problem.\n",
    "\n",
    "\n",
    "#### C:\n",
    "\n",
    "The C parameter is the *regularization parameter* in SVM. \n",
    "It controls the trade-off between maximizing the margin (increasing C) and \n",
    "minimizing the classification error on the training data.\n",
    "\n",
    "A smaller value of C allows more misclassifications on the training data, which can lead to a wider margin, \n",
    "while a larger C value reduces the margin to correctly classify more training points.\n",
    "\n",
    "In the code, we set C=1.0, which is a common default value. \n",
    "\n",
    "You can experiment with different values of C to find the best trade-off between \n",
    "margin and classification accuracy.\n",
    "\n",
    "\n",
    "Overall, the SVM classifier with a specified kernel and C value aims to \n",
    "find an *optimal hyperplane* that effectively separates the data into different classes based on \n",
    "the TF-IDF vectors derived from the text data. \n",
    "\n",
    "It is one of the classical and widely used methods fortext classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Train an SVM classifier on the TF-IDF vectors\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)  # You can try different kernels and hyperparameters as well\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "###### Need to change these for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Extended Proprietors       0.00      0.00      0.00         5\n",
      "  Non-QCEW Employees       0.00      0.00      0.00         5\n",
      "      QCEW Employees       0.33      0.80      0.47         5\n",
      "       Self-Employed       0.50      0.20      0.29         5\n",
      "\n",
      "            accuracy                           0.25        20\n",
      "           macro avg       0.21      0.25      0.19        20\n",
      "        weighted avg       0.21      0.25      0.19        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the model on the testing set\n",
    "\n",
    "# ground truth-golden labels-y labels\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macro Average:\n",
    "\n",
    "Macro average calculates the *unweighted average of a metric* (e.g., precision, recall, F1-score) across all classes.\n",
    "\n",
    "It treats each class equally, regardless of the class's size or number of samples. \n",
    "It is useful when you want to assess the model's performance without considering class imbalances. \n",
    "\n",
    "Macro average gives equal importance to each class, so it can be useful when all classes are equally important.\n",
    "\n",
    "#### Weighted Average:\n",
    "\n",
    "Weighted average, on the other hand, calculates the *average of a metric while considering the class's support* \n",
    "(i.e., the number of samples belonging to that class). It gives more weight to classes with more samples, \n",
    "which means larger classes have a greater impact on the overall average. \n",
    "\n",
    "Weighted average is useful when there are class imbalances, and you want to account for \n",
    "the fact that some classes have more impact on the overall performance.\n",
    "\n",
    "#### Support:\n",
    "\n",
    "The support is simply the *number of samples in each class*. \n",
    "\n",
    "It provides information about the distribution of the classes in the test dataset. \n",
    "For instance, if some classes have very few samples, \n",
    "it may indicate that the model's performance on those classes might be less reliable due to limited data.\n",
    "\n",
    "\n",
    "When evaluating a multi-class classifier, you typically get classification metrics like \n",
    "*precision*, *recall*, and *F1-score* for each class separately. \n",
    "\n",
    "Macro average and weighted average provide a way to summarize these class-wise metrics and \n",
    "get an overall understanding of the model's performance across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible problems:\n",
    "\n",
    "#### Class Imbalance:\n",
    "\n",
    "If the training data is heavily imbalanced, where one or more classes have very few samples compared to the others,\n",
    "the model may struggle to learn the characteristics of the minority classes, \n",
    "resulting in poor performance on those classes.\n",
    "\n",
    "#### Insufficient Data:\n",
    "\n",
    "If a particular class has very few training samples or is not well-represented in the training data, \n",
    "the model may not be able to generalize well for that class during testing.\n",
    "\n",
    "#### Overfitting:\n",
    "\n",
    "If the model is overfitting to the majority classes, it may ignore the patterns in the minority classes, \n",
    "leading to poor performance on those classes.\n",
    "\n",
    "#### Model Complexity:\n",
    "\n",
    "The chosen model may not be suitable for the specific dataset, or \n",
    "its complexity might not match the data's complexity. \n",
    "Different algorithms or model configurations might perform better on the given dataset.\"\"\"\n",
    "\n",
    "### Solutions:\n",
    "\n",
    "#### Data Augmentation:\n",
    "\n",
    "If possible, consider augmenting the data for the underrepresented classes to increase the number of training samples.\n",
    "\n",
    "#### Class Balancing Techniques:\n",
    "\n",
    "Use techniques like *oversampling* (e.g., *SMOTE8* - Synthetic Minority Over-sampling Technique) or \n",
    "*undersampling* to balance the class distribution.\n",
    "\n",
    "#### Hyperparameter Tuning:\n",
    "\n",
    "Experiment with different hyperparameter settings for the model, including *regularization*, *kernel type*, and *complexity*, to find the optimal configuration for better performance on all classes.\n",
    "\n",
    "#### Model Selection: \n",
    "\n",
    "Try using different algorithms and compare their performance to determine which one is better suited for your dataset.\n",
    "\n",
    "#### Error Analysis: \n",
    "\n",
    "Conduct an error analysis to understand the types of mistakes the model is making for the problematic classes. \n",
    "This insight can help identify the root causes and guide improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step for Anna:\n",
    "\n",
    "**Random Forest:** Random Forest is an ensemble learning method that uses multiple decision trees to make predictions. It is robust, handles non-linear relationships well, and can handle large datasets effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the required libraries.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.svm import SVC\n",
    "# from sklean.random_forest import random forest ###### Need to figure this out\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the text data and split the data into training and testing sets.\n",
    "\n",
    "###### We already have the slipt from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Vectorize the 'OCCID_NAME' text data using TF-IDF\n",
    "\n",
    "###### We already vectoreized above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train an Random Forest classifier on the TF-IDF vectors\n",
    "\n",
    "#svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "#svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "###### Need to figure this out fro Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the model on the testing set ###### Copied from above to be modified\n",
    "\n",
    "# ground truth-golden labels-y labels\n",
    "#y_pred = svm_classifier.predict(X_test_tfidf) ###### Modify this line\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Trees:** Decision Trees are simple and interpretable classifiers that can handle both numerical and categorical data. However, they may overfit the data if not pruned properly.\n",
    "\n",
    "**Gradient Boosting:** Gradient Boosting is an ensemble technique that combines multiple weak learners (usually decision trees) to create a powerful classifier. It often performs well and can handle complex relationships.\n",
    "\n",
    "**K-Nearest Neighbors (KNN):** KNN is a lazy learning algorithm that classifies samples based on \n",
    "\n",
    "**ensemble models:** Decision Trees + K-Nearest Neighbors (KNN) the majority class of their k nearest neighbors in the feature space. It is simple and can handle non-linear decision boundaries.\n",
    "\n",
    "**Naive Bayes:** Naive Bayes is based on Bayes' theorem and assumes that features are conditionally independent given the class label. It is efficient and works well with high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b290c12635df1505ccfaef9fc3c1b35db2a6d850878c7b98eea17e8fd25a874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
